[current_batch: 00100] loss: 2.027, learning rate: 0.000100
[current_batch: 00200] loss: 2.025, learning rate: 0.000100
[current_batch: 00300] loss: 2.072, learning rate: 0.000100
[current_batch: 00400] loss: 1.899, learning rate: 0.000100
[current_batch: 00500] loss: 2.113, learning rate: 0.000100
[current_batch: 00600] loss: 2.003, learning rate: 0.000100
[current_batch: 00700] loss: 1.966, learning rate: 0.000100
[current_batch: 00800] loss: 2.061, learning rate: 0.000100
model restored!
optimizer restored!
current_batch restored!
[current_batch: 00600] loss: 1.995, learning rate: 0.000100
[current_batch: 00700] loss: 1.950, learning rate: 0.000100
[current_batch: 00800] loss: 1.731, learning rate: 0.000100
[current_batch: 00900] loss: 1.763, learning rate: 0.000100
[current_batch: 01000] loss: 1.715, learning rate: 0.000100
Starting validation ...
val: 0.7684, 0.7361, 0.7682
[current_batch: 01100] loss: 1.777, learning rate: 0.000100
[current_batch: 01200] loss: 1.750, learning rate: 0.000100
[current_batch: 01300] loss: 1.816, learning rate: 0.000100
[current_batch: 01400] loss: 1.757, learning rate: 0.000100
[current_batch: 01500] loss: 1.811, learning rate: 0.000100
[current_batch: 01600] loss: 1.811, learning rate: 0.000100
[current_batch: 01700] loss: 1.933, learning rate: 0.000100
[current_batch: 01800] loss: 1.709, learning rate: 0.000100
[current_batch: 01900] loss: 1.682, learning rate: 0.000100
[current_batch: 02000] loss: 1.762, learning rate: 0.000100
Starting validation ...
val: 0.7743, 0.7400, 0.7739
[current_batch: 02100] loss: 1.711, learning rate: 0.000100
[current_batch: 02200] loss: 1.639, learning rate: 0.000100
[current_batch: 02300] loss: 1.586, learning rate: 0.000100
[current_batch: 02400] loss: 1.682, learning rate: 0.000100
[current_batch: 02500] loss: 1.708, learning rate: 0.000100
[current_batch: 02600] loss: 1.642, learning rate: 0.000100
[current_batch: 02700] loss: 1.704, learning rate: 0.000100
[current_batch: 02800] loss: 1.718, learning rate: 0.000100
[current_batch: 02900] loss: 1.735, learning rate: 0.000100
[current_batch: 03000] loss: 1.632, learning rate: 0.000100
Starting validation ...
val: 0.7693, 0.7333, 0.7688
[current_batch: 03100] loss: 1.681, learning rate: 0.000100
[current_batch: 03200] loss: 1.698, learning rate: 0.000100
[current_batch: 03300] loss: 1.935, learning rate: 0.000100
[current_batch: 03400] loss: 1.705, learning rate: 0.000100
[current_batch: 03500] loss: 1.775, learning rate: 0.000100
[current_batch: 03600] loss: 1.779, learning rate: 0.000100
[current_batch: 03700] loss: 1.838, learning rate: 0.000100
[current_batch: 03800] loss: 1.790, learning rate: 0.000100
[current_batch: 03900] loss: 1.663, learning rate: 0.000100
[current_batch: 04000] loss: 1.677, learning rate: 0.000100
Starting validation ...
val: 0.7942, 0.7658, 0.7941
[current_batch: 04100] loss: 1.613, learning rate: 0.000100
[current_batch: 04200] loss: 1.661, learning rate: 0.000100
[current_batch: 04300] loss: 1.697, learning rate: 0.000100
[current_batch: 04400] loss: 1.823, learning rate: 0.000100
[current_batch: 04500] loss: 1.627, learning rate: 0.000100
[current_batch: 04600] loss: 1.720, learning rate: 0.000100
[current_batch: 04700] loss: 1.727, learning rate: 0.000100
[current_batch: 04800] loss: 1.735, learning rate: 0.000100
[current_batch: 04900] loss: 1.857, learning rate: 0.000100
[current_batch: 05000] loss: 1.744, learning rate: 0.000100
Starting validation ...
val: 0.7802, 0.7460, 0.7798
[current_batch: 05100] loss: 1.649, learning rate: 0.000100
[current_batch: 05200] loss: 1.761, learning rate: 0.000100
[current_batch: 05300] loss: 1.645, learning rate: 0.000100
[current_batch: 05400] loss: 1.773, learning rate: 0.000100
[current_batch: 05500] loss: 1.598, learning rate: 0.000100
[current_batch: 05600] loss: 1.661, learning rate: 0.000100
[current_batch: 05700] loss: 1.641, learning rate: 0.000100
[current_batch: 05800] loss: 1.739, learning rate: 0.000100
[current_batch: 05900] loss: 1.660, learning rate: 0.000100
[current_batch: 06000] loss: 1.775, learning rate: 0.000100
Starting validation ...
val: 0.7835, 0.7489, 0.7831
[current_batch: 06100] loss: 1.645, learning rate: 0.000100
[current_batch: 06200] loss: 1.703, learning rate: 0.000100
[current_batch: 06300] loss: 1.738, learning rate: 0.000100
[current_batch: 06400] loss: 1.778, learning rate: 0.000100
[current_batch: 06500] loss: 1.653, learning rate: 0.000100
[current_batch: 06600] loss: 1.700, learning rate: 0.000100
[current_batch: 06700] loss: 1.797, learning rate: 0.000100
[current_batch: 06800] loss: 1.684, learning rate: 0.000100
[current_batch: 06900] loss: 1.721, learning rate: 0.000100
[current_batch: 07000] loss: 1.691, learning rate: 0.000100
Starting validation ...
val: 0.7863, 0.7514, 0.7859
[current_batch: 07100] loss: 1.690, learning rate: 0.000100
[current_batch: 07200] loss: 1.738, learning rate: 0.000100
[current_batch: 07300] loss: 1.581, learning rate: 0.000100
[current_batch: 07400] loss: 1.747, learning rate: 0.000100
[current_batch: 07500] loss: 1.663, learning rate: 0.000100
[current_batch: 07600] loss: 1.750, learning rate: 0.000100
[current_batch: 07700] loss: 1.644, learning rate: 0.000100
[current_batch: 07800] loss: 1.757, learning rate: 0.000100
[current_batch: 07900] loss: 1.706, learning rate: 0.000100
[current_batch: 08000] loss: 1.619, learning rate: 0.000100
Starting validation ...
val: 0.7814, 0.7455, 0.7809
[current_batch: 08100] loss: 1.582, learning rate: 0.000100
[current_batch: 08200] loss: 1.694, learning rate: 0.000100
[current_batch: 08300] loss: 1.706, learning rate: 0.000100
[current_batch: 08400] loss: 1.678, learning rate: 0.000100
[current_batch: 08500] loss: 1.674, learning rate: 0.000100
[current_batch: 08600] loss: 1.758, learning rate: 0.000100
[current_batch: 08700] loss: 1.634, learning rate: 0.000100
[current_batch: 08800] loss: 1.675, learning rate: 0.000100
[current_batch: 08900] loss: 1.579, learning rate: 0.000100
[current_batch: 09000] loss: 1.745, learning rate: 0.000100
Starting validation ...
val: 0.7844, 0.7487, 0.7839
[current_batch: 09100] loss: 1.687, learning rate: 0.000100
[current_batch: 09200] loss: 1.764, learning rate: 0.000100
[current_batch: 09300] loss: 1.721, learning rate: 0.000100
[current_batch: 09400] loss: 1.686, learning rate: 0.000100
[current_batch: 09500] loss: 1.742, learning rate: 0.000100
[current_batch: 09600] loss: 1.665, learning rate: 0.000100
[current_batch: 09700] loss: 1.645, learning rate: 0.000100
[current_batch: 09800] loss: 1.673, learning rate: 0.000100
[current_batch: 09900] loss: 1.640, learning rate: 0.000100
[current_batch: 10000] loss: 1.647, learning rate: 0.000100
Starting validation ...
val: 0.7738, 0.7374, 0.7733
[current_batch: 10100] loss: 1.704, learning rate: 0.000100
[current_batch: 10200] loss: 1.666, learning rate: 0.000100
[current_batch: 10300] loss: 1.715, learning rate: 0.000100
[current_batch: 10400] loss: 1.725, learning rate: 0.000100
[current_batch: 10500] loss: 1.610, learning rate: 0.000100
[current_batch: 10600] loss: 1.589, learning rate: 0.000100
[current_batch: 10700] loss: 1.797, learning rate: 0.000100
[current_batch: 10800] loss: 1.663, learning rate: 0.000100
[current_batch: 10900] loss: 1.663, learning rate: 0.000100
[current_batch: 11000] loss: 1.707, learning rate: 0.000100
Starting validation ...
val: 0.7777, 0.7418, 0.7772
[current_batch: 11100] loss: 1.699, learning rate: 0.000100
[current_batch: 11200] loss: 1.709, learning rate: 0.000100
[current_batch: 11300] loss: 1.617, learning rate: 0.000100
[current_batch: 11400] loss: 1.652, learning rate: 0.000100
[current_batch: 11500] loss: 1.725, learning rate: 0.000100
[current_batch: 11600] loss: 1.644, learning rate: 0.000100
[current_batch: 11700] loss: 1.686, learning rate: 0.000100
[current_batch: 11800] loss: 1.728, learning rate: 0.000100
[current_batch: 11900] loss: 1.666, learning rate: 0.000100
[current_batch: 12000] loss: 1.742, learning rate: 0.000100
Starting validation ...
val: 0.7751, 0.7389, 0.7746
[current_batch: 12100] loss: 1.691, learning rate: 0.000100
[current_batch: 12200] loss: 1.751, learning rate: 0.000100
[current_batch: 12300] loss: 1.580, learning rate: 0.000100
[current_batch: 12400] loss: 1.696, learning rate: 0.000100
[current_batch: 12500] loss: 1.741, learning rate: 0.000100
[current_batch: 12600] loss: 1.694, learning rate: 0.000100
[current_batch: 12700] loss: 1.701, learning rate: 0.000100
[current_batch: 12800] loss: 1.576, learning rate: 0.000100
[current_batch: 12900] loss: 1.626, learning rate: 0.000100
[current_batch: 13000] loss: 1.715, learning rate: 0.000100
Starting validation ...
val: 0.7747, 0.7385, 0.7742
[current_batch: 13100] loss: 1.704, learning rate: 0.000100
[current_batch: 13200] loss: 1.620, learning rate: 0.000100
[current_batch: 13300] loss: 1.662, learning rate: 0.000100
[current_batch: 13400] loss: 1.781, learning rate: 0.000100
[current_batch: 13500] loss: 1.757, learning rate: 0.000100
[current_batch: 13600] loss: 1.645, learning rate: 0.000100
[current_batch: 13700] loss: 1.784, learning rate: 0.000100
[current_batch: 13800] loss: 1.619, learning rate: 0.000100
[current_batch: 13900] loss: 1.684, learning rate: 0.000100
[current_batch: 14000] loss: 1.750, learning rate: 0.000100
Starting validation ...
val: 0.7726, 0.7368, 0.7721
[current_batch: 14100] loss: 1.663, learning rate: 0.000100
[current_batch: 14200] loss: 1.662, learning rate: 0.000100
[current_batch: 14300] loss: 1.673, learning rate: 0.000100
[current_batch: 14400] loss: 1.684, learning rate: 0.000100
[current_batch: 14500] loss: 1.701, learning rate: 0.000100
[current_batch: 14600] loss: 1.658, learning rate: 0.000100
[current_batch: 14700] loss: 1.639, learning rate: 0.000100
[current_batch: 14800] loss: 1.649, learning rate: 0.000100
[current_batch: 14900] loss: 1.622, learning rate: 0.000100
[current_batch: 15000] loss: 1.688, learning rate: 0.000100
Starting validation ...
val: 0.7782, 0.7428, 0.7778
[current_batch: 15100] loss: 1.624, learning rate: 0.000100
[current_batch: 15200] loss: 1.696, learning rate: 0.000100
Starting validation ...
val: 0.7791, 0.7440, 0.7786
[current_batch: 15300] loss: 1.177, learning rate: 0.000100
[current_batch: 15400] loss: 1.752, learning rate: 0.000100
[current_batch: 15500] loss: 1.704, learning rate: 0.000100
[current_batch: 15600] loss: 1.735, learning rate: 0.000100
[current_batch: 15700] loss: 1.749, learning rate: 0.000100
[current_batch: 15800] loss: 1.622, learning rate: 0.000100
[current_batch: 15900] loss: 1.709, learning rate: 0.000100
[current_batch: 16000] loss: 1.739, learning rate: 0.000100
Starting validation ...
val: 0.7842, 0.7495, 0.7837
[current_batch: 16100] loss: 1.623, learning rate: 0.000100
[current_batch: 16200] loss: 1.728, learning rate: 0.000100
[current_batch: 16300] loss: 1.670, learning rate: 0.000100
[current_batch: 16400] loss: 1.632, learning rate: 0.000100
[current_batch: 16500] loss: 1.654, learning rate: 0.000100
[current_batch: 16600] loss: 1.734, learning rate: 0.000100
[current_batch: 16700] loss: 1.619, learning rate: 0.000100
[current_batch: 16800] loss: 1.682, learning rate: 0.000100
[current_batch: 16900] loss: 1.607, learning rate: 0.000100
[current_batch: 17000] loss: 1.663, learning rate: 0.000100
Starting validation ...
val: 0.7818, 0.7465, 0.7813
[current_batch: 17100] loss: 1.484, learning rate: 0.000100
[current_batch: 17200] loss: 1.660, learning rate: 0.000100
[current_batch: 17300] loss: 1.612, learning rate: 0.000100
[current_batch: 17400] loss: 1.704, learning rate: 0.000100
[current_batch: 17500] loss: 1.648, learning rate: 0.000100
[current_batch: 17600] loss: 1.673, learning rate: 0.000100
[current_batch: 17700] loss: 1.732, learning rate: 0.000100
[current_batch: 17800] loss: 1.668, learning rate: 0.000100
[current_batch: 17900] loss: 1.640, learning rate: 0.000100
[current_batch: 18000] loss: 1.647, learning rate: 0.000100
Starting validation ...
val: 0.7829, 0.7479, 0.7825
[current_batch: 18100] loss: 1.751, learning rate: 0.000100
[current_batch: 18200] loss: 1.734, learning rate: 0.000100
[current_batch: 18300] loss: 1.579, learning rate: 0.000100
[current_batch: 18400] loss: 1.682, learning rate: 0.000100
[current_batch: 18500] loss: 1.666, learning rate: 0.000100
[current_batch: 18600] loss: 1.598, learning rate: 0.000100
[current_batch: 18700] loss: 1.769, learning rate: 0.000100
[current_batch: 18800] loss: 1.753, learning rate: 0.000100
[current_batch: 18900] loss: 1.559, learning rate: 0.000100
[current_batch: 19000] loss: 1.633, learning rate: 0.000100
Starting validation ...
val: 0.7784, 0.7427, 0.7779
[current_batch: 19100] loss: 1.725, learning rate: 0.000100
[current_batch: 19200] loss: 1.680, learning rate: 0.000100
[current_batch: 19300] loss: 1.677, learning rate: 0.000100
[current_batch: 19400] loss: 1.642, learning rate: 0.000100
[current_batch: 19500] loss: 1.676, learning rate: 0.000100
[current_batch: 19600] loss: 1.671, learning rate: 0.000100
[current_batch: 19700] loss: 1.604, learning rate: 0.000100
[current_batch: 19800] loss: 1.640, learning rate: 0.000100
[current_batch: 19900] loss: 1.675, learning rate: 0.000100
[current_batch: 20000] loss: 1.708, learning rate: 0.000100
Starting validation ...
val: 0.7800, 0.7441, 0.7795
[current_batch: 20100] loss: 1.660, learning rate: 0.000100
[current_batch: 20200] loss: 1.598, learning rate: 0.000100
[current_batch: 20300] loss: 1.555, learning rate: 0.000100
[current_batch: 20400] loss: 1.662, learning rate: 0.000100
[current_batch: 20500] loss: 1.679, learning rate: 0.000100
[current_batch: 20600] loss: 1.612, learning rate: 0.000100
[current_batch: 20700] loss: 1.670, learning rate: 0.000100
[current_batch: 20800] loss: 1.671, learning rate: 0.000100
[current_batch: 20900] loss: 1.659, learning rate: 0.000100
[current_batch: 21000] loss: 1.545, learning rate: 0.000100
Starting validation ...
val: 0.7784, 0.7424, 0.7780
[current_batch: 21100] loss: 1.728, learning rate: 0.000100
[current_batch: 21200] loss: 1.589, learning rate: 0.000100
[current_batch: 21300] loss: 1.639, learning rate: 0.000100
[current_batch: 21400] loss: 1.638, learning rate: 0.000100
[current_batch: 21500] loss: 1.696, learning rate: 0.000100
[current_batch: 21600] loss: 1.814, learning rate: 0.000100
[current_batch: 21700] loss: 1.636, learning rate: 0.000100
[current_batch: 21800] loss: 1.643, learning rate: 0.000100
[current_batch: 21900] loss: 1.732, learning rate: 0.000100
[current_batch: 22000] loss: 1.702, learning rate: 0.000100
Starting validation ...
val: 0.7870, 0.7524, 0.7866
[current_batch: 22100] loss: 1.683, learning rate: 0.000100
[current_batch: 22200] loss: 1.697, learning rate: 0.000100
[current_batch: 22300] loss: 1.756, learning rate: 0.000100
[current_batch: 22400] loss: 1.586, learning rate: 0.000100
[current_batch: 22500] loss: 1.756, learning rate: 0.000100
[current_batch: 22600] loss: 1.686, learning rate: 0.000100
[current_batch: 22700] loss: 1.731, learning rate: 0.000100
[current_batch: 22800] loss: 1.734, learning rate: 0.000100
[current_batch: 22900] loss: 1.701, learning rate: 0.000100
[current_batch: 23000] loss: 1.648, learning rate: 0.000100
Starting validation ...
val: 0.7883, 0.7538, 0.7879
[current_batch: 23100] loss: 1.666, learning rate: 0.000100
[current_batch: 23200] loss: 1.641, learning rate: 0.000100
[current_batch: 23300] loss: 1.785, learning rate: 0.000100
[current_batch: 23400] loss: 1.639, learning rate: 0.000100
[current_batch: 23500] loss: 1.557, learning rate: 0.000100
[current_batch: 23600] loss: 1.652, learning rate: 0.000100
[current_batch: 23700] loss: 1.577, learning rate: 0.000100
[current_batch: 23800] loss: 1.697, learning rate: 0.000100
[current_batch: 23900] loss: 1.681, learning rate: 0.000100
[current_batch: 24000] loss: 1.606, learning rate: 0.000100
Starting validation ...
val: 0.7813, 0.7461, 0.7809
[current_batch: 24100] loss: 1.681, learning rate: 0.000100
[current_batch: 24200] loss: 1.745, learning rate: 0.000100
[current_batch: 24300] loss: 1.595, learning rate: 0.000100
[current_batch: 24400] loss: 1.648, learning rate: 0.000100
[current_batch: 24500] loss: 1.579, learning rate: 0.000100
[current_batch: 24600] loss: 1.571, learning rate: 0.000100
[current_batch: 24700] loss: 1.646, learning rate: 0.000100
[current_batch: 24800] loss: 1.705, learning rate: 0.000100
[current_batch: 24900] loss: 1.620, learning rate: 0.000100
[current_batch: 25000] loss: 1.641, learning rate: 0.000100
Starting validation ...
val: 0.7814, 0.7463, 0.7810
[current_batch: 25100] loss: 1.558, learning rate: 0.000100
[current_batch: 25200] loss: 1.580, learning rate: 0.000100
[current_batch: 25300] loss: 1.671, learning rate: 0.000100
[current_batch: 25400] loss: 1.708, learning rate: 0.000100
[current_batch: 25500] loss: 1.614, learning rate: 0.000100
[current_batch: 25600] loss: 1.763, learning rate: 0.000100
[current_batch: 25700] loss: 1.571, learning rate: 0.000100
[current_batch: 25800] loss: 1.767, learning rate: 0.000100
[current_batch: 25900] loss: 1.716, learning rate: 0.000100
[current_batch: 26000] loss: 1.669, learning rate: 0.000100
Starting validation ...
val: 0.7801, 0.7451, 0.7797
[current_batch: 26100] loss: 1.648, learning rate: 0.000100
[current_batch: 26200] loss: 1.740, learning rate: 0.000100
[current_batch: 26300] loss: 1.677, learning rate: 0.000100
[current_batch: 26400] loss: 1.755, learning rate: 0.000100
[current_batch: 26500] loss: 1.635, learning rate: 0.000100
[current_batch: 26600] loss: 1.662, learning rate: 0.000100
[current_batch: 26700] loss: 1.761, learning rate: 0.000100
[current_batch: 26800] loss: 1.623, learning rate: 0.000100
[current_batch: 26900] loss: 1.641, learning rate: 0.000100
[current_batch: 27000] loss: 1.743, learning rate: 0.000100
Starting validation ...
val: 0.7799, 0.7444, 0.7795
[current_batch: 27100] loss: 1.608, learning rate: 0.000100
[current_batch: 27200] loss: 1.681, learning rate: 0.000100
[current_batch: 27300] loss: 1.712, learning rate: 0.000100
[current_batch: 27400] loss: 1.670, learning rate: 0.000100
[current_batch: 27500] loss: 1.701, learning rate: 0.000100
[current_batch: 27600] loss: 1.582, learning rate: 0.000100
[current_batch: 27700] loss: 1.654, learning rate: 0.000100
[current_batch: 27800] loss: 1.473, learning rate: 0.000100
[current_batch: 27900] loss: 1.616, learning rate: 0.000100
[current_batch: 28000] loss: 1.643, learning rate: 0.000100
Starting validation ...
val: 0.7829, 0.7478, 0.7825
[current_batch: 28100] loss: 1.628, learning rate: 0.000100
[current_batch: 28200] loss: 1.714, learning rate: 0.000100
[current_batch: 28300] loss: 1.640, learning rate: 0.000100
[current_batch: 28400] loss: 1.498, learning rate: 0.000100
[current_batch: 28500] loss: 1.598, learning rate: 0.000100
[current_batch: 28600] loss: 1.623, learning rate: 0.000100
[current_batch: 28700] loss: 1.742, learning rate: 0.000100
[current_batch: 28800] loss: 1.530, learning rate: 0.000100
[current_batch: 28900] loss: 1.692, learning rate: 0.000100
[current_batch: 29000] loss: 1.606, learning rate: 0.000100
Starting validation ...
val: 0.7864, 0.7519, 0.7860
[current_batch: 29100] loss: 1.565, learning rate: 0.000100
[current_batch: 29200] loss: 1.681, learning rate: 0.000100
[current_batch: 29300] loss: 1.747, learning rate: 0.000100
[current_batch: 29400] loss: 1.644, learning rate: 0.000100
[current_batch: 29500] loss: 1.692, learning rate: 0.000100
[current_batch: 29600] loss: 1.545, learning rate: 0.000100
[current_batch: 29700] loss: 1.568, learning rate: 0.000100
[current_batch: 29800] loss: 1.625, learning rate: 0.000100
[current_batch: 29900] loss: 1.617, learning rate: 0.000100
Starting validation ...
val: 0.7832, 0.7487, 0.7829
[current_batch: 30000] loss: 0.764, learning rate: 0.000100
Starting validation ...
val: 0.7834, 0.7487, 0.7830
[current_batch: 30100] loss: 1.643, learning rate: 0.000100
[current_batch: 30200] loss: 1.505, learning rate: 0.000100
[current_batch: 30300] loss: 1.646, learning rate: 0.000100
[current_batch: 30400] loss: 1.707, learning rate: 0.000100
[current_batch: 30500] loss: 1.583, learning rate: 0.000100
[current_batch: 30600] loss: 1.718, learning rate: 0.000100
[current_batch: 30700] loss: 1.662, learning rate: 0.000100
[current_batch: 30800] loss: 1.699, learning rate: 0.000100
[current_batch: 30900] loss: 1.677, learning rate: 0.000100
[current_batch: 31000] loss: 1.621, learning rate: 0.000100
Starting validation ...
val: 0.7902, 0.7562, 0.7898
[current_batch: 31100] loss: 1.608, learning rate: 0.000100
[current_batch: 31200] loss: 1.614, learning rate: 0.000100
[current_batch: 31300] loss: 1.541, learning rate: 0.000100
[current_batch: 31400] loss: 1.563, learning rate: 0.000100
[current_batch: 31500] loss: 1.473, learning rate: 0.000100
[current_batch: 31600] loss: 1.768, learning rate: 0.000100
[current_batch: 31700] loss: 1.617, learning rate: 0.000100
[current_batch: 31800] loss: 1.712, learning rate: 0.000100
[current_batch: 31900] loss: 1.684, learning rate: 0.000100
[current_batch: 32000] loss: 1.700, learning rate: 0.000100
Starting validation ...
val: 0.7923, 0.7584, 0.7920
[current_batch: 32100] loss: 1.631, learning rate: 0.000100
[current_batch: 32200] loss: 1.698, learning rate: 0.000100
[current_batch: 32300] loss: 1.645, learning rate: 0.000100
[current_batch: 32400] loss: 1.636, learning rate: 0.000100
[current_batch: 32500] loss: 1.662, learning rate: 0.000100
[current_batch: 32600] loss: 1.746, learning rate: 0.000100
[current_batch: 32700] loss: 1.612, learning rate: 0.000100
[current_batch: 32800] loss: 1.698, learning rate: 0.000100
[current_batch: 32900] loss: 1.679, learning rate: 0.000100
[current_batch: 33000] loss: 1.568, learning rate: 0.000100
Starting validation ...
val: 0.7855, 0.7505, 0.7851
[current_batch: 33100] loss: 1.734, learning rate: 0.000100
[current_batch: 33200] loss: 1.578, learning rate: 0.000100
[current_batch: 33300] loss: 1.597, learning rate: 0.000100
[current_batch: 33400] loss: 1.555, learning rate: 0.000100
[current_batch: 33500] loss: 1.584, learning rate: 0.000100
[current_batch: 33600] loss: 1.775, learning rate: 0.000100
[current_batch: 33700] loss: 1.721, learning rate: 0.000100
[current_batch: 33800] loss: 1.591, learning rate: 0.000100
[current_batch: 33900] loss: 1.631, learning rate: 0.000100
[current_batch: 34000] loss: 1.731, learning rate: 0.000100
Starting validation ...
val: 0.7851, 0.7498, 0.7846
[current_batch: 34100] loss: 1.641, learning rate: 0.000100
[current_batch: 34200] loss: 1.709, learning rate: 0.000100
[current_batch: 34300] loss: 1.668, learning rate: 0.000100
[current_batch: 34400] loss: 1.669, learning rate: 0.000100
[current_batch: 34500] loss: 1.684, learning rate: 0.000100
[current_batch: 34600] loss: 1.642, learning rate: 0.000100
[current_batch: 34700] loss: 1.709, learning rate: 0.000100
[current_batch: 34800] loss: 1.664, learning rate: 0.000100
[current_batch: 34900] loss: 1.599, learning rate: 0.000100
[current_batch: 35000] loss: 1.747, learning rate: 0.000100
Starting validation ...
val: 0.7844, 0.7491, 0.7840
[current_batch: 35100] loss: 1.649, learning rate: 0.000100
[current_batch: 35200] loss: 1.628, learning rate: 0.000100
[current_batch: 35300] loss: 1.668, learning rate: 0.000100
[current_batch: 35400] loss: 1.697, learning rate: 0.000100
[current_batch: 35500] loss: 1.669, learning rate: 0.000100
[current_batch: 35600] loss: 1.522, learning rate: 0.000100
[current_batch: 35700] loss: 1.687, learning rate: 0.000100
[current_batch: 35800] loss: 1.701, learning rate: 0.000100
[current_batch: 35900] loss: 1.608, learning rate: 0.000100
[current_batch: 36000] loss: 1.555, learning rate: 0.000100
Starting validation ...
val: 0.7840, 0.7489, 0.7836
[current_batch: 36100] loss: 1.703, learning rate: 0.000100
[current_batch: 36200] loss: 1.586, learning rate: 0.000100
[current_batch: 36300] loss: 1.536, learning rate: 0.000100
[current_batch: 36400] loss: 1.528, learning rate: 0.000100
[current_batch: 36500] loss: 1.506, learning rate: 0.000100
[current_batch: 36600] loss: 1.600, learning rate: 0.000100
[current_batch: 36700] loss: 1.634, learning rate: 0.000100
[current_batch: 36800] loss: 1.645, learning rate: 0.000100
[current_batch: 36900] loss: 1.551, learning rate: 0.000100
[current_batch: 37000] loss: 1.657, learning rate: 0.000100
Starting validation ...
val: 0.7875, 0.7529, 0.7871
[current_batch: 37100] loss: 1.683, learning rate: 0.000100
[current_batch: 37200] loss: 1.698, learning rate: 0.000100
[current_batch: 37300] loss: 1.744, learning rate: 0.000100
[current_batch: 37400] loss: 1.735, learning rate: 0.000100
[current_batch: 37500] loss: 1.665, learning rate: 0.000100
[current_batch: 37600] loss: 1.612, learning rate: 0.000100
[current_batch: 37700] loss: 1.681, learning rate: 0.000100
[current_batch: 37800] loss: 1.658, learning rate: 0.000100
[current_batch: 37900] loss: 1.697, learning rate: 0.000100
[current_batch: 38000] loss: 1.685, learning rate: 0.000100
Starting validation ...
val: 0.7881, 0.7538, 0.7877
[current_batch: 38100] loss: 1.740, learning rate: 0.000100
[current_batch: 38200] loss: 1.626, learning rate: 0.000100
[current_batch: 38300] loss: 1.634, learning rate: 0.000100
[current_batch: 38400] loss: 1.585, learning rate: 0.000100
[current_batch: 38500] loss: 1.636, learning rate: 0.000100
[current_batch: 38600] loss: 1.780, learning rate: 0.000100
[current_batch: 38700] loss: 1.624, learning rate: 0.000100
[current_batch: 38800] loss: 1.684, learning rate: 0.000100
[current_batch: 38900] loss: 1.650, learning rate: 0.000100
[current_batch: 39000] loss: 1.681, learning rate: 0.000100
Starting validation ...
val: 0.7854, 0.7507, 0.7849
[current_batch: 39100] loss: 1.634, learning rate: 0.000100
[current_batch: 39200] loss: 1.675, learning rate: 0.000100
[current_batch: 39300] loss: 1.657, learning rate: 0.000100
[current_batch: 39400] loss: 1.659, learning rate: 0.000100
[current_batch: 39500] loss: 1.652, learning rate: 0.000100
[current_batch: 39600] loss: 1.601, learning rate: 0.000100
[current_batch: 39700] loss: 1.653, learning rate: 0.000100
[current_batch: 39800] loss: 1.686, learning rate: 0.000100
[current_batch: 39900] loss: 1.669, learning rate: 0.000100
[current_batch: 40000] loss: 1.531, learning rate: 0.000100
Starting validation ...
val: 0.7876, 0.7526, 0.7872
[current_batch: 40100] loss: 1.660, learning rate: 0.000100
[current_batch: 40200] loss: 1.634, learning rate: 0.000100
[current_batch: 40300] loss: 1.627, learning rate: 0.000100
[current_batch: 40400] loss: 1.695, learning rate: 0.000100
[current_batch: 40500] loss: 1.697, learning rate: 0.000100
[current_batch: 40600] loss: 1.715, learning rate: 0.000100
[current_batch: 40700] loss: 1.647, learning rate: 0.000100
[current_batch: 40800] loss: 1.663, learning rate: 0.000100
[current_batch: 40900] loss: 1.697, learning rate: 0.000100
[current_batch: 41000] loss: 1.569, learning rate: 0.000100
Starting validation ...
val: 0.7842, 0.7490, 0.7837
[current_batch: 41100] loss: 1.693, learning rate: 0.000100
[current_batch: 41200] loss: 1.661, learning rate: 0.000100
[current_batch: 41300] loss: 1.632, learning rate: 0.000100
[current_batch: 41400] loss: 1.515, learning rate: 0.000100
[current_batch: 41500] loss: 1.612, learning rate: 0.000100
[current_batch: 41600] loss: 1.621, learning rate: 0.000100
[current_batch: 41700] loss: 1.681, learning rate: 0.000100
[current_batch: 41800] loss: 1.573, learning rate: 0.000100
[current_batch: 41900] loss: 1.689, learning rate: 0.000100
[current_batch: 42000] loss: 1.718, learning rate: 0.000100
Starting validation ...
val: 0.7865, 0.7517, 0.7861
[current_batch: 42100] loss: 1.597, learning rate: 0.000100
[current_batch: 42200] loss: 1.605, learning rate: 0.000100
[current_batch: 42300] loss: 1.615, learning rate: 0.000100
[current_batch: 42400] loss: 1.646, learning rate: 0.000100
[current_batch: 42500] loss: 1.621, learning rate: 0.000100
[current_batch: 42600] loss: 1.647, learning rate: 0.000100
[current_batch: 42700] loss: 1.568, learning rate: 0.000100
[current_batch: 42800] loss: 1.670, learning rate: 0.000100
[current_batch: 42900] loss: 1.596, learning rate: 0.000100
[current_batch: 43000] loss: 1.683, learning rate: 0.000100
Starting validation ...
val: 0.7852, 0.7504, 0.7848
[current_batch: 43100] loss: 1.749, learning rate: 0.000100
[current_batch: 43200] loss: 1.564, learning rate: 0.000100
[current_batch: 43300] loss: 1.667, learning rate: 0.000100
[current_batch: 43400] loss: 1.565, learning rate: 0.000100
[current_batch: 43500] loss: 1.724, learning rate: 0.000100
[current_batch: 43600] loss: 1.732, learning rate: 0.000100
[current_batch: 43700] loss: 1.569, learning rate: 0.000100
[current_batch: 43800] loss: 1.638, learning rate: 0.000100
[current_batch: 43900] loss: 1.607, learning rate: 0.000100
[current_batch: 44000] loss: 1.727, learning rate: 0.000100
Starting validation ...
val: 0.7872, 0.7529, 0.7868
[current_batch: 44100] loss: 1.619, learning rate: 0.000100
[current_batch: 44200] loss: 1.634, learning rate: 0.000100
[current_batch: 44300] loss: 1.665, learning rate: 0.000100
[current_batch: 44400] loss: 1.597, learning rate: 0.000100
[current_batch: 44500] loss: 1.622, learning rate: 0.000100
[current_batch: 44600] loss: 1.682, learning rate: 0.000100
Starting validation ...
val: 0.7863, 0.7523, 0.7859
[current_batch: 44700] loss: 0.206, learning rate: 0.000100
[current_batch: 44800] loss: 1.604, learning rate: 0.000100
[current_batch: 44900] loss: 1.626, learning rate: 0.000100
[current_batch: 45000] loss: 1.721, learning rate: 0.000100
Starting validation ...
val: 0.7851, 0.7509, 0.7847
[current_batch: 45100] loss: 1.846, learning rate: 0.000100
[current_batch: 45200] loss: 1.711, learning rate: 0.000100
[current_batch: 45300] loss: 1.649, learning rate: 0.000100
[current_batch: 45400] loss: 1.552, learning rate: 0.000100
[current_batch: 45500] loss: 1.725, learning rate: 0.000100
[current_batch: 45600] loss: 1.602, learning rate: 0.000100
[current_batch: 45700] loss: 1.722, learning rate: 0.000100
[current_batch: 45800] loss: 1.703, learning rate: 0.000100
[current_batch: 45900] loss: 1.702, learning rate: 0.000100
[current_batch: 46000] loss: 1.616, learning rate: 0.000100
Starting validation ...
val: 0.7829, 0.7485, 0.7825
[current_batch: 46100] loss: 1.604, learning rate: 0.000100
[current_batch: 46200] loss: 1.601, learning rate: 0.000100
[current_batch: 46300] loss: 1.648, learning rate: 0.000100
[current_batch: 46400] loss: 1.590, learning rate: 0.000100
[current_batch: 46500] loss: 1.738, learning rate: 0.000100
[current_batch: 46600] loss: 1.631, learning rate: 0.000100
[current_batch: 46700] loss: 1.583, learning rate: 0.000100
[current_batch: 46800] loss: 1.680, learning rate: 0.000100
[current_batch: 46900] loss: 1.701, learning rate: 0.000100
[current_batch: 47000] loss: 1.582, learning rate: 0.000100
Starting validation ...
val: 0.7857, 0.7513, 0.7853
[current_batch: 47100] loss: 1.587, learning rate: 0.000100
[current_batch: 47200] loss: 1.680, learning rate: 0.000100
[current_batch: 47300] loss: 1.641, learning rate: 0.000100
[current_batch: 47400] loss: 1.567, learning rate: 0.000100
[current_batch: 47500] loss: 1.677, learning rate: 0.000100
[current_batch: 47600] loss: 1.680, learning rate: 0.000100
[current_batch: 47700] loss: 1.687, learning rate: 0.000100
[current_batch: 47800] loss: 1.564, learning rate: 0.000100
[current_batch: 47900] loss: 1.680, learning rate: 0.000100
[current_batch: 48000] loss: 1.796, learning rate: 0.000100
Starting validation ...
val: 0.7869, 0.7523, 0.7865
[current_batch: 48100] loss: 1.624, learning rate: 0.000100
[current_batch: 48200] loss: 1.664, learning rate: 0.000100
[current_batch: 48300] loss: 1.705, learning rate: 0.000100
[current_batch: 48400] loss: 1.552, learning rate: 0.000100
[current_batch: 48500] loss: 1.684, learning rate: 0.000100
[current_batch: 48600] loss: 1.578, learning rate: 0.000100
[current_batch: 48700] loss: 1.597, learning rate: 0.000100
[current_batch: 48800] loss: 1.638, learning rate: 0.000100
[current_batch: 48900] loss: 1.638, learning rate: 0.000100
[current_batch: 49000] loss: 1.625, learning rate: 0.000100
Starting validation ...
val: 0.7853, 0.7504, 0.7849
[current_batch: 49100] loss: 1.660, learning rate: 0.000100
[current_batch: 49200] loss: 1.708, learning rate: 0.000100
[current_batch: 49300] loss: 1.704, learning rate: 0.000100
[current_batch: 49400] loss: 1.558, learning rate: 0.000100
[current_batch: 49500] loss: 1.601, learning rate: 0.000100
[current_batch: 49600] loss: 1.627, learning rate: 0.000100
[current_batch: 49700] loss: 1.607, learning rate: 0.000100
[current_batch: 49800] loss: 1.582, learning rate: 0.000100
[current_batch: 49900] loss: 1.523, learning rate: 0.000100
[current_batch: 50000] loss: 1.620, learning rate: 0.000100
Starting validation ...
val: 0.7868, 0.7518, 0.7863
[current_batch: 50100] loss: 1.633, learning rate: 0.000100
[current_batch: 50200] loss: 1.626, learning rate: 0.000100
[current_batch: 50300] loss: 1.563, learning rate: 0.000100
[current_batch: 50400] loss: 1.647, learning rate: 0.000100
[current_batch: 50500] loss: 1.668, learning rate: 0.000100
[current_batch: 50600] loss: 1.801, learning rate: 0.000100
[current_batch: 50700] loss: 1.562, learning rate: 0.000100
[current_batch: 50800] loss: 1.762, learning rate: 0.000100
[current_batch: 50900] loss: 1.550, learning rate: 0.000100
[current_batch: 51000] loss: 1.586, learning rate: 0.000100
Starting validation ...
val: 0.7902, 0.7557, 0.7898
[current_batch: 51100] loss: 1.518, learning rate: 0.000100
[current_batch: 51200] loss: 1.506, learning rate: 0.000100
[current_batch: 51300] loss: 1.453, learning rate: 0.000100
[current_batch: 51400] loss: 1.680, learning rate: 0.000100
[current_batch: 51500] loss: 1.758, learning rate: 0.000100
[current_batch: 51600] loss: 1.637, learning rate: 0.000100
[current_batch: 51700] loss: 1.641, learning rate: 0.000100
[current_batch: 51800] loss: 1.629, learning rate: 0.000100
[current_batch: 51900] loss: 1.703, learning rate: 0.000100
[current_batch: 52000] loss: 1.613, learning rate: 0.000100
Starting validation ...
val: 0.7895, 0.7552, 0.7892
[current_batch: 52100] loss: 1.592, learning rate: 0.000100
[current_batch: 52200] loss: 1.673, learning rate: 0.000100
[current_batch: 52300] loss: 1.659, learning rate: 0.000100
[current_batch: 52400] loss: 1.548, learning rate: 0.000100
[current_batch: 52500] loss: 1.561, learning rate: 0.000100
[current_batch: 52600] loss: 1.592, learning rate: 0.000100
[current_batch: 52700] loss: 1.656, learning rate: 0.000100
[current_batch: 52800] loss: 1.596, learning rate: 0.000100
[current_batch: 52900] loss: 1.553, learning rate: 0.000100
[current_batch: 53000] loss: 1.501, learning rate: 0.000100
Starting validation ...
val: 0.7865, 0.7516, 0.7861
[current_batch: 53100] loss: 1.611, learning rate: 0.000100
[current_batch: 53200] loss: 1.674, learning rate: 0.000100
[current_batch: 53300] loss: 1.636, learning rate: 0.000100
[current_batch: 53400] loss: 1.595, learning rate: 0.000100
[current_batch: 53500] loss: 1.650, learning rate: 0.000100
[current_batch: 53600] loss: 1.700, learning rate: 0.000100
[current_batch: 53700] loss: 1.600, learning rate: 0.000100
[current_batch: 53800] loss: 1.749, learning rate: 0.000100
[current_batch: 53900] loss: 1.696, learning rate: 0.000100
[current_batch: 54000] loss: 1.698, learning rate: 0.000100
Starting validation ...
val: 0.7892, 0.7553, 0.7888
[current_batch: 54100] loss: 1.613, learning rate: 0.000100
[current_batch: 54200] loss: 1.672, learning rate: 0.000100
[current_batch: 54300] loss: 1.583, learning rate: 0.000100
[current_batch: 54400] loss: 1.582, learning rate: 0.000100
[current_batch: 54500] loss: 1.718, learning rate: 0.000100
[current_batch: 54600] loss: 1.594, learning rate: 0.000100
[current_batch: 54700] loss: 1.615, learning rate: 0.000100
[current_batch: 54800] loss: 1.636, learning rate: 0.000100
[current_batch: 54900] loss: 1.661, learning rate: 0.000100
[current_batch: 55000] loss: 1.571, learning rate: 0.000100
Starting validation ...
val: 0.7885, 0.7544, 0.7881
[current_batch: 55100] loss: 1.640, learning rate: 0.000100
[current_batch: 55200] loss: 1.675, learning rate: 0.000100
[current_batch: 55300] loss: 1.654, learning rate: 0.000100
[current_batch: 55400] loss: 1.625, learning rate: 0.000100
[current_batch: 55500] loss: 1.648, learning rate: 0.000100
[current_batch: 55600] loss: 1.582, learning rate: 0.000100
[current_batch: 55700] loss: 1.598, learning rate: 0.000100
[current_batch: 55800] loss: 1.591, learning rate: 0.000100
[current_batch: 55900] loss: 1.663, learning rate: 0.000100
[current_batch: 56000] loss: 1.591, learning rate: 0.000100
Starting validation ...
val: 0.7897, 0.7556, 0.7894
[current_batch: 56100] loss: 1.609, learning rate: 0.000100
[current_batch: 56200] loss: 1.637, learning rate: 0.000100
[current_batch: 56300] loss: 1.680, learning rate: 0.000100
[current_batch: 56400] loss: 1.623, learning rate: 0.000100
[current_batch: 56500] loss: 1.600, learning rate: 0.000100
[current_batch: 56600] loss: 1.555, learning rate: 0.000100
[current_batch: 56700] loss: 1.629, learning rate: 0.000100
[current_batch: 56800] loss: 1.609, learning rate: 0.000100
[current_batch: 56900] loss: 1.654, learning rate: 0.000100
[current_batch: 57000] loss: 1.489, learning rate: 0.000100
Starting validation ...
val: 0.7926, 0.7586, 0.7922
[current_batch: 57100] loss: 1.594, learning rate: 0.000100
[current_batch: 57200] loss: 1.583, learning rate: 0.000100
[current_batch: 57300] loss: 1.726, learning rate: 0.000100
[current_batch: 57400] loss: 1.718, learning rate: 0.000100
[current_batch: 57500] loss: 1.579, learning rate: 0.000100
[current_batch: 57600] loss: 1.568, learning rate: 0.000100
[current_batch: 57700] loss: 1.707, learning rate: 0.000100
[current_batch: 57800] loss: 1.519, learning rate: 0.000100
[current_batch: 57900] loss: 1.608, learning rate: 0.000100
[current_batch: 58000] loss: 1.640, learning rate: 0.000100
Starting validation ...
val: 0.7909, 0.7568, 0.7906
[current_batch: 58100] loss: 1.660, learning rate: 0.000100
[current_batch: 58200] loss: 1.605, learning rate: 0.000100
[current_batch: 58300] loss: 1.723, learning rate: 0.000100
[current_batch: 58400] loss: 1.572, learning rate: 0.000100
[current_batch: 58500] loss: 1.614, learning rate: 0.000100
[current_batch: 58600] loss: 1.673, learning rate: 0.000100
[current_batch: 58700] loss: 1.667, learning rate: 0.000100
[current_batch: 58800] loss: 1.712, learning rate: 0.000100
[current_batch: 58900] loss: 1.780, learning rate: 0.000100
[current_batch: 59000] loss: 1.661, learning rate: 0.000100
Starting validation ...
val: 0.7902, 0.7562, 0.7899
[current_batch: 59100] loss: 1.731, learning rate: 0.000100
[current_batch: 59200] loss: 1.605, learning rate: 0.000100
[current_batch: 59300] loss: 1.651, learning rate: 0.000100
[current_batch: 59400] loss: 1.587, learning rate: 0.000100
Starting validation ...
val: 0.7901, 0.7561, 0.7897
[current_batch: 59500] loss: 1.508, learning rate: 0.000100
[current_batch: 59600] loss: 1.615, learning rate: 0.000100
[current_batch: 59700] loss: 1.565, learning rate: 0.000100
[current_batch: 59800] loss: 1.647, learning rate: 0.000100
[current_batch: 59900] loss: 1.679, learning rate: 0.000100
[current_batch: 60000] loss: 1.612, learning rate: 0.000100
Starting validation ...
val: 0.7938, 0.7604, 0.7935
[current_batch: 60100] loss: 1.560, learning rate: 0.000100
[current_batch: 60200] loss: 1.639, learning rate: 0.000100
[current_batch: 60300] loss: 1.548, learning rate: 0.000100
[current_batch: 60400] loss: 1.557, learning rate: 0.000100
[current_batch: 60500] loss: 1.637, learning rate: 0.000100
[current_batch: 60600] loss: 1.647, learning rate: 0.000100
[current_batch: 60700] loss: 1.644, learning rate: 0.000100
[current_batch: 60800] loss: 1.625, learning rate: 0.000100
[current_batch: 60900] loss: 1.704, learning rate: 0.000100
[current_batch: 61000] loss: 1.593, learning rate: 0.000100
Starting validation ...
val: 0.7945, 0.7610, 0.7942
[current_batch: 61100] loss: 1.641, learning rate: 0.000100
[current_batch: 61200] loss: 1.532, learning rate: 0.000100
[current_batch: 61300] loss: 1.597, learning rate: 0.000100
[current_batch: 61400] loss: 1.704, learning rate: 0.000100
[current_batch: 61500] loss: 1.615, learning rate: 0.000100
[current_batch: 61600] loss: 1.736, learning rate: 0.000100
[current_batch: 61700] loss: 1.663, learning rate: 0.000100
[current_batch: 61800] loss: 1.638, learning rate: 0.000100
[current_batch: 61900] loss: 1.570, learning rate: 0.000100
[current_batch: 62000] loss: 1.618, learning rate: 0.000100
Starting validation ...
val: 0.7954, 0.7622, 0.7951
[current_batch: 62100] loss: 1.768, learning rate: 0.000100
[current_batch: 62200] loss: 1.635, learning rate: 0.000100
[current_batch: 62300] loss: 1.646, learning rate: 0.000100
[current_batch: 62400] loss: 1.608, learning rate: 0.000100
[current_batch: 62500] loss: 1.646, learning rate: 0.000100
[current_batch: 62600] loss: 1.703, learning rate: 0.000100
[current_batch: 62700] loss: 1.625, learning rate: 0.000100
[current_batch: 62800] loss: 1.507, learning rate: 0.000100
[current_batch: 62900] loss: 1.569, learning rate: 0.000100
[current_batch: 63000] loss: 1.516, learning rate: 0.000100
Starting validation ...
val: 0.7900, 0.7564, 0.7896
[current_batch: 63100] loss: 1.591, learning rate: 0.000100
[current_batch: 63200] loss: 1.504, learning rate: 0.000100
[current_batch: 63300] loss: 1.647, learning rate: 0.000100
[current_batch: 63400] loss: 1.628, learning rate: 0.000100
[current_batch: 63500] loss: 1.636, learning rate: 0.000100
[current_batch: 63600] loss: 1.572, learning rate: 0.000100
[current_batch: 63700] loss: 1.587, learning rate: 0.000100
[current_batch: 63800] loss: 1.596, learning rate: 0.000100
[current_batch: 63900] loss: 1.725, learning rate: 0.000100
[current_batch: 64000] loss: 1.666, learning rate: 0.000100
Starting validation ...
val: 0.7921, 0.7586, 0.7917
[current_batch: 64100] loss: 1.638, learning rate: 0.000100
[current_batch: 64200] loss: 1.615, learning rate: 0.000100
[current_batch: 64300] loss: 1.597, learning rate: 0.000100
[current_batch: 64400] loss: 1.651, learning rate: 0.000100
[current_batch: 64500] loss: 1.614, learning rate: 0.000100
[current_batch: 64600] loss: 1.691, learning rate: 0.000100
[current_batch: 64700] loss: 1.685, learning rate: 0.000100
[current_batch: 64800] loss: 1.619, learning rate: 0.000100
[current_batch: 64900] loss: 1.667, learning rate: 0.000100
[current_batch: 65000] loss: 1.603, learning rate: 0.000100
Starting validation ...
val: 0.7879, 0.7539, 0.7875
[current_batch: 65100] loss: 1.742, learning rate: 0.000100
[current_batch: 65200] loss: 1.585, learning rate: 0.000100
[current_batch: 65300] loss: 1.615, learning rate: 0.000100
[current_batch: 65400] loss: 1.621, learning rate: 0.000100
[current_batch: 65500] loss: 1.598, learning rate: 0.000100
[current_batch: 65600] loss: 1.694, learning rate: 0.000100
[current_batch: 65700] loss: 1.529, learning rate: 0.000100
[current_batch: 65800] loss: 1.557, learning rate: 0.000100
[current_batch: 65900] loss: 1.620, learning rate: 0.000100
[current_batch: 66000] loss: 1.768, learning rate: 0.000100
Starting validation ...
val: 0.7921, 0.7582, 0.7917
[current_batch: 66100] loss: 1.563, learning rate: 0.000100
[current_batch: 66200] loss: 1.778, learning rate: 0.000100
[current_batch: 66300] loss: 1.734, learning rate: 0.000100
[current_batch: 66400] loss: 1.616, learning rate: 0.000100
[current_batch: 66500] loss: 1.633, learning rate: 0.000100
[current_batch: 66600] loss: 1.636, learning rate: 0.000100
[current_batch: 66700] loss: 1.640, learning rate: 0.000100
[current_batch: 66800] loss: 1.515, learning rate: 0.000100
[current_batch: 66900] loss: 1.694, learning rate: 0.000100
[current_batch: 67000] loss: 1.657, learning rate: 0.000100
Starting validation ...
val: 0.7904, 0.7563, 0.7900
[current_batch: 67100] loss: 1.579, learning rate: 0.000100
[current_batch: 67200] loss: 1.550, learning rate: 0.000100
[current_batch: 67300] loss: 1.559, learning rate: 0.000100
[current_batch: 67400] loss: 1.519, learning rate: 0.000100
[current_batch: 67500] loss: 1.775, learning rate: 0.000100
[current_batch: 67600] loss: 1.600, learning rate: 0.000100
[current_batch: 67700] loss: 1.604, learning rate: 0.000100
[current_batch: 67800] loss: 1.562, learning rate: 0.000100
[current_batch: 67900] loss: 1.507, learning rate: 0.000100
[current_batch: 68000] loss: 1.622, learning rate: 0.000100
Starting validation ...
val: 0.7911, 0.7573, 0.7907
[current_batch: 68100] loss: 1.702, learning rate: 0.000100
[current_batch: 68200] loss: 1.568, learning rate: 0.000100
[current_batch: 68300] loss: 1.806, learning rate: 0.000100
[current_batch: 68400] loss: 1.654, learning rate: 0.000100
[current_batch: 68500] loss: 1.662, learning rate: 0.000100
[current_batch: 68600] loss: 1.526, learning rate: 0.000100
[current_batch: 68700] loss: 1.627, learning rate: 0.000100
[current_batch: 68800] loss: 1.668, learning rate: 0.000100
[current_batch: 68900] loss: 1.560, learning rate: 0.000100
[current_batch: 69000] loss: 1.671, learning rate: 0.000100
Starting validation ...
val: 0.7929, 0.7592, 0.7925
[current_batch: 69100] loss: 1.576, learning rate: 0.000100
[current_batch: 69200] loss: 1.717, learning rate: 0.000100
[current_batch: 69300] loss: 1.608, learning rate: 0.000100
[current_batch: 69400] loss: 1.571, learning rate: 0.000100
[current_batch: 69500] loss: 1.590, learning rate: 0.000100
[current_batch: 69600] loss: 1.652, learning rate: 0.000100
[current_batch: 69700] loss: 1.610, learning rate: 0.000100
[current_batch: 69800] loss: 1.660, learning rate: 0.000100
[current_batch: 69900] loss: 1.553, learning rate: 0.000100
[current_batch: 70000] loss: 1.559, learning rate: 0.000100
Starting validation ...
val: 0.7926, 0.7592, 0.7923
[current_batch: 70100] loss: 1.620, learning rate: 0.000100
[current_batch: 70200] loss: 1.680, learning rate: 0.000100
[current_batch: 70300] loss: 1.702, learning rate: 0.000100
[current_batch: 70400] loss: 1.674, learning rate: 0.000100
[current_batch: 70500] loss: 1.618, learning rate: 0.000100
[current_batch: 70600] loss: 1.599, learning rate: 0.000100
[current_batch: 70700] loss: 1.606, learning rate: 0.000100
[current_batch: 70800] loss: 1.675, learning rate: 0.000100
[current_batch: 70900] loss: 1.600, learning rate: 0.000100
[current_batch: 71000] loss: 1.626, learning rate: 0.000100
Starting validation ...
val: 0.7938, 0.7604, 0.7934
[current_batch: 71100] loss: 1.712, learning rate: 0.000100
[current_batch: 71200] loss: 1.726, learning rate: 0.000100
[current_batch: 71300] loss: 1.646, learning rate: 0.000100
[current_batch: 71400] loss: 1.590, learning rate: 0.000100
[current_batch: 71500] loss: 1.686, learning rate: 0.000100
[current_batch: 71600] loss: 1.700, learning rate: 0.000100
[current_batch: 71700] loss: 1.532, learning rate: 0.000100
[current_batch: 71800] loss: 1.704, learning rate: 0.000100
[current_batch: 71900] loss: 1.638, learning rate: 0.000100
[current_batch: 72000] loss: 1.660, learning rate: 0.000100
Starting validation ...
val: 0.7932, 0.7596, 0.7929
[current_batch: 72100] loss: 1.678, learning rate: 0.000100
[current_batch: 72200] loss: 1.645, learning rate: 0.000100
[current_batch: 72300] loss: 1.543, learning rate: 0.000100
[current_batch: 72400] loss: 1.673, learning rate: 0.000100
[current_batch: 72500] loss: 1.587, learning rate: 0.000100
[current_batch: 72600] loss: 1.606, learning rate: 0.000100
[current_batch: 72700] loss: 1.540, learning rate: 0.000100
[current_batch: 72800] loss: 1.611, learning rate: 0.000100
[current_batch: 72900] loss: 1.790, learning rate: 0.000100
[current_batch: 73000] loss: 1.602, learning rate: 0.000100
Starting validation ...
val: 0.7959, 0.7625, 0.7955
[current_batch: 73100] loss: 1.676, learning rate: 0.000100
[current_batch: 73200] loss: 1.619, learning rate: 0.000100
[current_batch: 73300] loss: 1.636, learning rate: 0.000100
[current_batch: 73400] loss: 1.623, learning rate: 0.000100
[current_batch: 73500] loss: 1.588, learning rate: 0.000100
[current_batch: 73600] loss: 1.599, learning rate: 0.000100
[current_batch: 73700] loss: 1.572, learning rate: 0.000100
[current_batch: 73800] loss: 1.538, learning rate: 0.000100
[current_batch: 73900] loss: 1.600, learning rate: 0.000100
[current_batch: 74000] loss: 1.629, learning rate: 0.000100
Starting validation ...
val: 0.7972, 0.7637, 0.7969
[current_batch: 74100] loss: 1.568, learning rate: 0.000100
Starting validation ...
val: 0.7967, 0.7631, 0.7963
[current_batch: 74200] loss: 0.907, learning rate: 0.000100
[current_batch: 74300] loss: 1.538, learning rate: 0.000100
[current_batch: 74400] loss: 1.613, learning rate: 0.000100
[current_batch: 74500] loss: 1.596, learning rate: 0.000100
[current_batch: 74600] loss: 1.619, learning rate: 0.000100
[current_batch: 74700] loss: 1.586, learning rate: 0.000100
[current_batch: 74800] loss: 1.576, learning rate: 0.000100
[current_batch: 74900] loss: 1.630, learning rate: 0.000100
[current_batch: 75000] loss: 1.574, learning rate: 0.000100
Starting validation ...
val: 0.7958, 0.7620, 0.7955
[current_batch: 75100] loss: 1.667, learning rate: 0.000100
[current_batch: 75200] loss: 1.576, learning rate: 0.000100
[current_batch: 75300] loss: 1.568, learning rate: 0.000100
[current_batch: 75400] loss: 1.619, learning rate: 0.000100
[current_batch: 75500] loss: 1.636, learning rate: 0.000100
[current_batch: 75600] loss: 1.621, learning rate: 0.000100
[current_batch: 75700] loss: 1.520, learning rate: 0.000100
[current_batch: 75800] loss: 1.576, learning rate: 0.000100
[current_batch: 75900] loss: 1.573, learning rate: 0.000100
[current_batch: 76000] loss: 1.471, learning rate: 0.000100
Starting validation ...
val: 0.7946, 0.7607, 0.7942
[current_batch: 76100] loss: 1.546, learning rate: 0.000100
[current_batch: 76200] loss: 1.670, learning rate: 0.000100
[current_batch: 76300] loss: 1.629, learning rate: 0.000100
[current_batch: 76400] loss: 1.600, learning rate: 0.000100
[current_batch: 76500] loss: 1.621, learning rate: 0.000100
[current_batch: 76600] loss: 1.666, learning rate: 0.000100
[current_batch: 76700] loss: 1.678, learning rate: 0.000100
[current_batch: 76800] loss: 1.642, learning rate: 0.000100
[current_batch: 76900] loss: 1.714, learning rate: 0.000100
[current_batch: 77000] loss: 1.550, learning rate: 0.000100
Starting validation ...
val: 0.7944, 0.7609, 0.7941
[current_batch: 77100] loss: 1.508, learning rate: 0.000100
[current_batch: 77200] loss: 1.633, learning rate: 0.000100
[current_batch: 77300] loss: 1.574, learning rate: 0.000100
[current_batch: 77400] loss: 1.614, learning rate: 0.000100
[current_batch: 77500] loss: 1.694, learning rate: 0.000100
[current_batch: 77600] loss: 1.633, learning rate: 0.000100
[current_batch: 77700] loss: 1.699, learning rate: 0.000100
[current_batch: 77800] loss: 1.599, learning rate: 0.000100
[current_batch: 77900] loss: 1.708, learning rate: 0.000100
[current_batch: 78000] loss: 1.734, learning rate: 0.000100
Starting validation ...
val: 0.7972, 0.7635, 0.7968
[current_batch: 78100] loss: 1.567, learning rate: 0.000100
[current_batch: 78200] loss: 1.667, learning rate: 0.000100
[current_batch: 78300] loss: 1.559, learning rate: 0.000100
[current_batch: 78400] loss: 1.565, learning rate: 0.000100
[current_batch: 78500] loss: 1.632, learning rate: 0.000100
[current_batch: 78600] loss: 1.650, learning rate: 0.000100
[current_batch: 78700] loss: 1.720, learning rate: 0.000100
[current_batch: 78800] loss: 1.586, learning rate: 0.000100
[current_batch: 78900] loss: 1.509, learning rate: 0.000100
[current_batch: 79000] loss: 1.583, learning rate: 0.000100
Starting validation ...
val: 0.7995, 0.7667, 0.7992
[current_batch: 79100] loss: 1.513, learning rate: 0.000100
[current_batch: 79200] loss: 1.606, learning rate: 0.000100
[current_batch: 79300] loss: 1.605, learning rate: 0.000100
[current_batch: 79400] loss: 1.561, learning rate: 0.000100
[current_batch: 79500] loss: 1.712, learning rate: 0.000100
[current_batch: 79600] loss: 1.504, learning rate: 0.000100
[current_batch: 79700] loss: 1.670, learning rate: 0.000100
[current_batch: 79800] loss: 1.569, learning rate: 0.000100
[current_batch: 79900] loss: 1.612, learning rate: 0.000100
[current_batch: 80000] loss: 1.655, learning rate: 0.000100
Starting validation ...
val: 0.7998, 0.7667, 0.7995
[current_batch: 80100] loss: 1.620, learning rate: 0.000100
[current_batch: 80200] loss: 1.627, learning rate: 0.000100
[current_batch: 80300] loss: 1.513, learning rate: 0.000100
[current_batch: 80400] loss: 1.680, learning rate: 0.000100
[current_batch: 80500] loss: 1.595, learning rate: 0.000100
[current_batch: 80600] loss: 1.679, learning rate: 0.000100
[current_batch: 80700] loss: 1.667, learning rate: 0.000100
[current_batch: 80800] loss: 1.681, learning rate: 0.000100
[current_batch: 80900] loss: 1.531, learning rate: 0.000100
[current_batch: 81000] loss: 1.682, learning rate: 0.000100
Starting validation ...
val: 0.7960, 0.7626, 0.7957
[current_batch: 81100] loss: 1.688, learning rate: 0.000100
[current_batch: 81200] loss: 1.602, learning rate: 0.000100
[current_batch: 81300] loss: 1.517, learning rate: 0.000100
[current_batch: 81400] loss: 1.748, learning rate: 0.000100
[current_batch: 81500] loss: 1.666, learning rate: 0.000100
[current_batch: 81600] loss: 1.642, learning rate: 0.000100
[current_batch: 81700] loss: 1.493, learning rate: 0.000100
